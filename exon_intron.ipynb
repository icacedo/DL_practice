{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47305123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# machine learning works with tables\n",
    "# rows are examples and columns are atributes\n",
    "# tensor = n-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072867a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in genDL repo\n",
    "# hi.true = high expression, true sites from highly expressed genes\n",
    "# lo.true = low expression\n",
    "# fakes have the same GT/AG site, but everything else is random\n",
    "# write something that takes the true set, fakes, and a fasta file as input\n",
    "# fasta is the thousands of examples of true or fake sites\n",
    "# use ex3 data for testing. ex5 has one replaced nucleotide.\n",
    "# tttcAG, where tttc can be tttc or cttt in ex3. AG does not change.\n",
    "# 3 files you want to use: hi.true, lo.true, ex3. trying to identify acceptor sites in ex3\n",
    "# when labeling data, run only acc or don at a time.\n",
    "# labels not for acc, don, they are positive/negative\n",
    "# 1 for positive, 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "# A: [1,0,0,0]\n",
    "# C: [0,1,0,0]\n",
    "# G: [0,0,1,0]\n",
    "# T: [0,0,0,1]\n",
    "# https://d2l.ai/chapter_preliminaries/pandas.html#reading-the-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bb0ae31",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got DataFrame)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m [inputs_true, inputs_false]\n\u001b[1;32m     42\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(encoded_data)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m inputs, outputs \u001b[38;5;241m=\u001b[39m encoded_data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m42\u001b[39m], encoded_data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m42\u001b[39m]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs_true\u001b[38;5;241m.\u001b[39mshape, inputs_false\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got DataFrame)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "\n",
    "def encoder(file):\n",
    "\n",
    "    fp = gzip.open(file)\n",
    "\n",
    "    one_hot = {\n",
    "        'A': [1,0,0,0],\n",
    "        'C': [0,1,0,0],\n",
    "        'G': [0,0,1,0],\n",
    "        'T': [0,0,0,1]\n",
    "    }\n",
    "\n",
    "    encoded = []\n",
    "\n",
    "    for line in fp:\n",
    "        onehot_seq = []\n",
    "        bstring = line.rstrip()\n",
    "        line = bstring.decode()\n",
    "        if line.startswith('>'): continue\n",
    "        for n in line:\n",
    "            onehot_seq.append(one_hot[n])\n",
    "        encoded.append(onehot_seq)\n",
    "\n",
    "    return encoded\n",
    "    \n",
    "encoded_true = encoder(\"data/acc.ex3.fa.gz\")\n",
    "encoded_false = encoder(\"data/acc.fake.txt.fa.gz\")\n",
    "\n",
    "inputs_true = pd.DataFrame(data = encoded_true)\n",
    "inputs_false = pd.DataFrame(data = encoded_false)\n",
    "\n",
    "label_true = [1]*len(encoded_true)\n",
    "label_false = [0]*len(encoded_false)\n",
    "\n",
    "inputs_true[\"label\"] = label_true\n",
    "inputs_false[\"label\"] = label_false\n",
    "\n",
    "encoded_data = [inputs_true, inputs_false]\n",
    "encoded_data = pd.concat(encoded_data)\n",
    "# need to convert onehot encoded lists into a tensor?\n",
    "torch.from_numpy(encoded_data)\n",
    "\n",
    "inputs, outputs = encoded_data.iloc[:, 0:42], encoded_data.iloc[:, 42]\n",
    "\n",
    "print(inputs_true.shape, inputs_false.shape)\n",
    "encoded_data.shape\n",
    "\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665792a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix in the reals and fakes for the input\n",
    "# two different labels\n",
    "# titanic who lives who dies ML practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf54a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d27ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
