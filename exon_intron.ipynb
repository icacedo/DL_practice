{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47305123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# machine learning works with tables\n",
    "# rows are examples and columns are atributes\n",
    "# tensor = n-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072867a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in genDL repo\n",
    "# hi.true = high expression, true sites from highly expressed genes\n",
    "# lo.true = low expression\n",
    "# fakes have the same GT/AG site, but everything else is random\n",
    "# write something that takes the true set, fakes, and a fasta file as input\n",
    "# fasta is the thousands of examples of true or fake sites\n",
    "# use ex3 data for testing. ex5 has one replaced nucleotide.\n",
    "# tttcAG, where tttc can be tttc or cttt in ex3. AG does not change.\n",
    "# 3 files you want to use: hi.true, lo.true, ex3. trying to identify acceptor sites in ex3\n",
    "# when labeling data, run only acc or don at a time.\n",
    "# labels not for acc, don, they are positive/negative\n",
    "# 1 for positive, 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcb9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "# A: [1,0,0,0]\n",
    "# C: [0,1,0,0]\n",
    "# G: [0,0,1,0]\n",
    "# T: [0,0,0,1]\n",
    "# https://d2l.ai/chapter_preliminaries/pandas.html#reading-the-dataset\n",
    "\n",
    "\n",
    "# need to re-do one-hot encoding\n",
    "# [1,0,0,0,0,1,0,0] is AC\n",
    "# NOT\n",
    "# [1,0,0,0][0,1,0,0] is AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb0ae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 43) (186671, 43)\n",
      "[[list([1, 0, 0, 0]) list([0, 0, 0, 1]) list([0, 0, 1, 0]) ...\n",
      "  list([0, 0, 1, 0]) list([1, 0, 0, 0]) list([1, 0, 0, 0])]\n",
      " [list([0, 0, 1, 0]) list([0, 1, 0, 0]) list([0, 1, 0, 0]) ...\n",
      "  list([0, 0, 1, 0]) list([1, 0, 0, 0]) list([0, 0, 1, 0])]\n",
      " [list([0, 0, 1, 0]) list([0, 1, 0, 0]) list([0, 1, 0, 0]) ...\n",
      "  list([0, 0, 0, 1]) list([0, 1, 0, 0]) list([0, 0, 1, 0])]\n",
      " ...\n",
      " [list([1, 0, 0, 0]) list([1, 0, 0, 0]) list([0, 0, 0, 1]) ...\n",
      "  list([0, 0, 0, 1]) list([0, 0, 1, 0]) list([1, 0, 0, 0])]\n",
      " [list([0, 1, 0, 0]) list([1, 0, 0, 0]) list([0, 0, 1, 0]) ...\n",
      "  list([0, 0, 1, 0]) list([0, 0, 0, 1]) list([0, 0, 0, 1])]\n",
      " [list([0, 0, 1, 0]) list([0, 0, 0, 1]) list([0, 0, 1, 0]) ...\n",
      "  list([0, 0, 0, 1]) list([0, 0, 0, 1]) list([0, 0, 1, 0])]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "\n",
    "def encoder(file):\n",
    "\n",
    "    fp = gzip.open(file)\n",
    "\n",
    "    one_hot = {\n",
    "        'A': [1,0,0,0],\n",
    "        'C': [0,1,0,0],\n",
    "        'G': [0,0,1,0],\n",
    "        'T': [0,0,0,1]\n",
    "    }\n",
    "\n",
    "    encoded = []\n",
    "\n",
    "    for line in fp:\n",
    "        onehot_seq = []\n",
    "        bstring = line.rstrip()\n",
    "        line = bstring.decode()\n",
    "        if line.startswith('>'): continue\n",
    "        for n in line:\n",
    "            onehot_seq.append(one_hot[n])\n",
    "        encoded.append(onehot_seq)\n",
    "\n",
    "    return encoded\n",
    "    \n",
    "encoded_true = encoder(\"data/acc.ex3.fa.gz\")\n",
    "encoded_false = encoder(\"data/acc.fake.txt.fa.gz\")\n",
    "\n",
    "inputs_true = pd.DataFrame(data = encoded_true)\n",
    "inputs_false = pd.DataFrame(data = encoded_false)\n",
    "\n",
    "label_true = [1]*len(encoded_true)\n",
    "label_false = [0]*len(encoded_false)\n",
    "\n",
    "inputs_true[\"label\"] = label_true\n",
    "inputs_false[\"label\"] = label_false\n",
    "\n",
    "encoded_data = [inputs_true, inputs_false]\n",
    "encoded_data = pd.concat(encoded_data)\n",
    "# need to convert onehot encoded lists into a tensor?\n",
    "#torch.from_numpy(encoded_data)\n",
    "\n",
    "inputs, outputs = encoded_data.iloc[:, 0:42], encoded_data.iloc[:, 42]\n",
    "\n",
    "print(inputs_true.shape, inputs_false.shape)\n",
    "encoded_data.shape\n",
    "print(inputs.values)\n",
    "#X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665792a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix in the reals and fakes for the input\n",
    "# two different labels\n",
    "# titanic who lives who dies ML practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf54a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22d27ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d24060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
    "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')\n",
    "    \n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8a69c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68fdb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b7bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162ed5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 1. 0.]\n",
      " [2. 0. 1.]\n",
      " [4. 0. 1.]\n",
      " [3. 0. 1.]]\n",
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.values)\n",
    "print(inputs)\n",
    "type(inputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33a3c56",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Field elements must be 2- or 3-tuples, got '0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_values \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_values)\n",
      "File \u001b[0;32m~/miniconda3/envs/splice/lib/python3.9/site-packages/pandas/core/construction.py:350\u001b[0m, in \u001b[0;36marray\u001b[0;34m(data, dtype, copy)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_timedelta64_ns_dtype(dtype):\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaArray\u001b[38;5;241m.\u001b[39m_from_sequence(data, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 350\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mPandasArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/splice/lib/python3.9/site-packages/pandas/core/arrays/numpy_.py:180\u001b[0m, in \u001b[0;36mPandasArray._from_sequence\u001b[0;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, PandasDtype):\n\u001b[1;32m    178\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39m_dtype\n\u001b[0;32m--> 180\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m scalars:\n\u001b[1;32m    182\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/splice/lib/python3.9/site-packages/numpy/core/_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Field elements must be 2- or 3-tuples, got '0'"
     ]
    }
   ],
   "source": [
    "test_values = pd.array([1,0,0,0],[0,0,1,0])\n",
    "print(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378dddd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
